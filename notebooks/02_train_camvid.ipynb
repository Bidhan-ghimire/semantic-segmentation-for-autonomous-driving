{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515c5fa9-0a08-459f-990e-c4f09794b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Saving because I don't want to red\n",
    "save_dir = \"data/CamVid/np_saves/256_256\"\n",
    "\n",
    "X_train = np.load(save_dir + \"/x_train.npy\")\n",
    "Y_train = np.load(save_dir+\"/y_train.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5775ca76-3b46-4456-bb8c-1cf5e07c6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from classification_models.tfkeras import Classifiers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "\n",
    "    model_input = keras.Input(shape=(image_size[0], image_size[1], 3))\n",
    "    \n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet18 = ResNet18(weights='imagenet',include_top=False, input_tensor=model_input)\n",
    "    \n",
    "    x = resnet18.get_layer(\"relu1\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size[0] // 4 // x.shape[1], image_size[1] // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    \n",
    "    input_b = resnet18.get_layer(\"stage2_unit1_relu1\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "    \n",
    "    input_a = tf.keras.layers.CenterCrop(input_b.shape[1], input_b.shape[2])(input_a)\n",
    "    \n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size[0] // x.shape[1], image_size[1] // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\",activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "    \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    \n",
    "    model.compile(\n",
    "                 optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                 loss=loss,\n",
    "                 metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52257746-f876-4d35-8219-3862c10f7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3Plus((256, 256), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744fa1b0-d0ff-4d2c-ac0e-b563b680f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 16:16:31.604971: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-03-23 16:16:34.162070: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-03-23 16:16:34.162638: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-03-23 16:16:34.162662: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2022-03-23 16:16:34.163025: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-03-23 16:16:34.163078: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 22s 83ms/step - loss: 0.6830 - accuracy: 0.7765 - val_loss: 2.0581 - val_accuracy: 0.3448\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.4838 - accuracy: 0.8329 - val_loss: 4.9828 - val_accuracy: 0.3109\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.4036 - accuracy: 0.8604 - val_loss: 6.3558 - val_accuracy: 0.1752\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.3606 - accuracy: 0.8747 - val_loss: 4.3947 - val_accuracy: 0.3365\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.3206 - accuracy: 0.8876 - val_loss: 3.1979 - val_accuracy: 0.3708\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.3014 - accuracy: 0.8942 - val_loss: 3.0685 - val_accuracy: 0.5067\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.2853 - accuracy: 0.8988 - val_loss: 1.3000 - val_accuracy: 0.7031\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.2763 - accuracy: 0.9018 - val_loss: 1.4780 - val_accuracy: 0.7066\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.2520 - accuracy: 0.9100 - val_loss: 0.4764 - val_accuracy: 0.8511\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.2343 - accuracy: 0.9160 - val_loss: 0.3798 - val_accuracy: 0.8761\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.2169 - accuracy: 0.9212 - val_loss: 0.3324 - val_accuracy: 0.8886\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.2066 - accuracy: 0.9238 - val_loss: 0.3106 - val_accuracy: 0.8920\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.2029 - accuracy: 0.9252 - val_loss: 0.3180 - val_accuracy: 0.8958\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1930 - accuracy: 0.9285 - val_loss: 0.3034 - val_accuracy: 0.8978\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.1869 - accuracy: 0.9299 - val_loss: 0.3027 - val_accuracy: 0.8985\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.1850 - accuracy: 0.9308 - val_loss: 0.3191 - val_accuracy: 0.8983\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1831 - accuracy: 0.9313 - val_loss: 0.3344 - val_accuracy: 0.8921\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1786 - accuracy: 0.9326 - val_loss: 0.2957 - val_accuracy: 0.9002\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1696 - accuracy: 0.9355 - val_loss: 0.2997 - val_accuracy: 0.9044\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.2471 - accuracy: 0.9114 - val_loss: 20.4026 - val_accuracy: 0.4924\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.3471 - accuracy: 0.8788 - val_loss: 0.5174 - val_accuracy: 0.8379\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.2405 - accuracy: 0.9129 - val_loss: 0.3387 - val_accuracy: 0.8831\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1989 - accuracy: 0.9264 - val_loss: 0.2874 - val_accuracy: 0.8999\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1749 - accuracy: 0.9342 - val_loss: 0.2805 - val_accuracy: 0.9033\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1630 - accuracy: 0.9381 - val_loss: 0.2951 - val_accuracy: 0.9003\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1558 - accuracy: 0.9404 - val_loss: 0.2959 - val_accuracy: 0.9044\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1501 - accuracy: 0.9421 - val_loss: 0.3003 - val_accuracy: 0.9040\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.1476 - accuracy: 0.9429 - val_loss: 0.3160 - val_accuracy: 0.9031\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1457 - accuracy: 0.9435 - val_loss: 0.3013 - val_accuracy: 0.9056\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1430 - accuracy: 0.9443 - val_loss: 0.3120 - val_accuracy: 0.9036\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.1420 - accuracy: 0.9446 - val_loss: 0.3156 - val_accuracy: 0.9039\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.1401 - accuracy: 0.9453 - val_loss: 0.3098 - val_accuracy: 0.9047\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 9s 79ms/step - loss: 0.1378 - accuracy: 0.9460 - val_loss: 0.3213 - val_accuracy: 0.9045\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 9s 79ms/step - loss: 0.1362 - accuracy: 0.9465 - val_loss: 0.3351 - val_accuracy: 0.9026\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto', restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train, epochs=100, verbose=1, batch_size=4,  validation_split=0.2, callbacks=[early_stopping_cb]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386a853f-54e6-464e-8bdf-f1c5aa510429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 16:21:41.656620: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/256_256_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuran/prashant/.conda/envs/tensorflow-env/lib/python3.9/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_models/256_256_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd7e7077-f7f2-49b7-ba93-0829f419794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"histories/256_256_model.json\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e7000-a8e0-4e1f-9800-5d6015bf6f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b36906-d3cf-4451-b0cc-adefccd7307a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
